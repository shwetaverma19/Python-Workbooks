{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd6e202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: 0.99\n",
      "Logistic Regression: 0.99\n",
      "Random Forest: 1.0\n",
      "Support Vector Machine: 0.99\n",
      "Artificial Neural Network: 0.995\n",
      "\n",
      "Best performing model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# There are 1000 reviews for restaurants and films in a collection in the csv file on\n",
    "# Brightspace. All those reviews are labeled with its category (either restaurant review or movie\n",
    "# review). Developing classifiers that could automatically determine whether a future\n",
    "# text body is a restaurant review or a movie review.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Step 1: Load and Prepare the Dataset\n",
    "dataset = pd.read_excel('file.xlsx')\n",
    "\n",
    "restaurant_reviews = dataset[dataset['label'] == 'restaurant'].iloc[:400]\n",
    "movie_reviews = dataset[dataset['label'] == 'movie'].iloc[:400]\n",
    "\n",
    "train_dataset = pd.concat([restaurant_reviews, movie_reviews], ignore_index=True)\n",
    "test_dataset = dataset.iloc[800:]\n",
    "\n",
    "train_reviews = train_dataset['review'].tolist()\n",
    "train_labels = train_dataset['label'].tolist()\n",
    "\n",
    "test_reviews = test_dataset['review'].tolist()\n",
    "test_labels = test_dataset['label'].tolist()\n",
    "\n",
    "# Step 2: Transform Reviews into TF-IDF Matrix\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    filtered_words = [word for word in lemmatized_words if word.lower() not in stopwords_set and word not in string.punctuation]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "preprocessed_train_reviews = [preprocess_text(review) for review in train_reviews]\n",
    "preprocessed_test_reviews = [preprocess_text(review) for review in test_reviews]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=5)\n",
    "train_features = vectorizer.fit_transform(preprocessed_train_reviews)\n",
    "test_features = vectorizer.transform(preprocessed_test_reviews)\n",
    "\n",
    "# Step 3: Train and Evaluate Models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Artificial Neural Network': MLPClassifier(hidden_layer_sizes=(4,), random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(train_features, train_labels)\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    results[model_name] = accuracy\n",
    "\n",
    "# Print accuracy results\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f'{model_name}: {accuracy}')\n",
    "\n",
    "# Determine the best performing model\n",
    "best_model = max(results, key=results.get)\n",
    "print(f'\\nBest performing model: {best_model}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
